use stellar::algebra::ndmethods::create_identity_matrix;
use stellar::algebra::ndmethods::tensor_mult;
use stellar::decomposition::qr::{qr_decompose, QrDecomposition};
use stellar::decomposition::lu::{lu_decompose, LuDecomposition};
use stellar::structure::ndarray::NdArray;

// #[cfg(target_arch = "x86_64")]
use rand::distr::StandardUniform;
use rand::prelude::*;
use rand::prelude::*;
use rand::Rng;
use rand_distr::Normal;
use rand_distr::StandardNormal;

// reading : https://en.wikipedia.org/wiki/Schur_complement
// when writing article write something about recursive / iterative defns and which info is
// available, ie why need to reverse iteration on QR


// move code into examples directory
// cargo run --example demo
const CONVERGENCE_CONDITION: f32 = 1e-6;

fn rayleigh_inverse_iteration(mut matrix: NdArray) -> NdArray {
    // (A - Iu)y = x;
    // x' = Q from QR(y)
    // let M := (A-Iu)
    // LU(M) -> solve => y
    // u' := rayleigh quotient of x
    debug_assert!(matrix.dims.len() == 2);
    debug_assert!(matrix.dims[0] == matrix.dims[1]);
    let n = matrix.dims[0];
    let mut current = generate_random_matrix(n, n);
    let mut u = vec![0_f32;n];
    let mut error = 1_f32;
    // for i in 0..20 {
    while CONVERGENCE_CONDITION < error {
        // transforms M' = (A - Iu + Iu - Iu')
        let previous = current.clone();
        estimate_eigenvalues(&mut u, &mut matrix, &current);
        let lu = lu_decompose(matrix.clone());
        // eigen is now y
        lu.solve_inplace(&mut current);
        let qr = qr_decompose(current.clone());
        current = qr.projection_matrix();
        error = frobenius_diff_norm(&current, &previous);
        println!("error: {error:?}");
    }
    current
}
    
fn generate_random_matrix(m:usize, n:usize) -> NdArray {
    let mut rng = rand::rng();
    let mut data = vec![0.0_f32; m * n];
    for i in 0..m {
        for j in 0..n {
            let val = rng.sample(StandardNormal);
            data[i * n + j] = val;
        }
    }
    NdArray {
        dims: vec![m, n],
        data,
    }
}

fn frobenius_diff_norm(a: &NdArray, b: &NdArray) -> f32 {
    // distance :: SS (sign*a[ij] - b[ij])^2
    // sign := a'b
    debug_assert!(a.dims == b.dims);
    let (rows, cols) = (a.dims[0], a.dims[1]);
    let mut error = 0_f32;
    for j in 0..cols {
        for i in 0..rows {
            let diff = a.data[i * cols + j] - b.data[i * cols + j];
            error += diff * diff;
        }
    }
    error.sqrt()
}

fn estimate_eigenvalues(u:&mut[f32], a: &mut NdArray, x:&NdArray) {
    // estimated via rayleigh quotient
    // x'Ax/x'x
    debug_assert_eq!(a.dims[0], a.dims[1]); 
    let n = a.dims[0];
    // center M to A ->  A-u +u = A
    for i in 0..n {
        a.data[i * n + i] += u[i];
    }
    // only desire the diagonal
    for d in 0..n {
        let mut w = vec![0f32;n];
        let mut numerator = 0_f32;
        let mut denominator = 0_f32;
        for i in 0..n {
            for k in 0..n {
                w[i] +=  a.data[ i * n + k] * x.data[k * n + d];
            }
        }
        for k in 0..n {
            numerator += w[k] * x.data[k * n + d];
            denominator += x.data[k * n + d] * x.data[k * n + d];
        }
        u[d] = numerator / denominator;
        // perterb M by new uii : A - u' 
        a.data[d * n + d] -= u[d];
    }
}


fn test_random_eigenvectors() {
    let n = 3;

    // Step 1: create a random symmetric matrix
    let mut rng = rand::rng();
    let mut data = vec![0.0_f32; n * n];
    for i in 0..n {
        for j in i..n {
            let val = rng.sample(StandardNormal);
            data[i * n + j] = val;
            data[j * n + i] = val; // symmetric
        }
    }
    let matrix = NdArray {
        dims: vec![n, n],
        data,
    };

    // Step 2: run your eigenvector decomposition
    let eigenvecs = rayleigh_inverse_iteration(matrix.clone());

    // Step 3: check orthonormality Q^T Q ~ I
    for i in 0..n {
        for j in 0..n {
            let mut dot = 0.0;
            for k in 0..n {
                dot += eigenvecs.data[k * n + i] * eigenvecs.data[k * n + j];
            }
            if i == j {
                assert!((dot - 1.0).abs() < 1e-4, "Column {} not normalized", i);
            } else {
                assert!(dot.abs() < 1e-4, "Columns {} and {} not orthogonal", i, j);
            }
        }
    }

    // Step 4: check eigenvector property A v ~ lambda v
    for col in 0..n {
        let mut a_v = vec![0.0; n];
        for i in 0..n {
            for j in 0..n {
                a_v[i] += matrix.data[i * n + j] * eigenvecs.data[j * n + col];
            }
        }

        // estimate lambda as ratio of norms
        let mut lambda_est = 0.0;
        let mut norm_v = 0.0;
        for i in 0..n {
            lambda_est += a_v[i] * eigenvecs.data[i * n + col];
            norm_v += eigenvecs.data[i * n + col].powi(2);
        }
        lambda_est /= norm_v;

        // check that A v ~ lambda v
        for i in 0..n {
            let diff = (a_v[i] - lambda_est * eigenvecs.data[i * n + col]).abs();
            assert!(
                diff < 1e-1,
                "Eigenvector column {} failed A v ~ lambda v, diff={}",
                col,
                diff
            );
        }
    }

    println!("All tests passed!");
}


fn main() {
    // it's in proto.bu
    test_random_eigenvectors();
}
